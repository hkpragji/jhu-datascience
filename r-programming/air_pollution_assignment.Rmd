---
title: "Programming Assignment 1: Air Pollution"
author: "Hiten Pragji"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: true
    number_sections: true
    latex_engine: xelatex
geometry: margin=0.75in
fontsize: 11pt
header-includes:
  - \usepackage{amsmath}
  - \usepackage{amssymb}
  - \usepackage{graphicx}
  - \usepackage[numbers]{natbib}
  - \usepackage{url}
  - \usepackage{caption}
  - \usepackage{notoccite}
  - \usepackage{enumitem}
  - \usepackage{caption}
  - \usepackage{xcolor}
  - \usepackage{titlesec}
  - \usepackage{parskip}
  - \usepackage{hyperref}
  - \usepackage{mathtools}
  - \usepackage{bm}
  - \usepackage{dsfont}
  - \usepackage{bigints}
  - \usepackage[nointlimits]{esint}
  - \usepackage{titlesec}
---

```{r setup, include = FALSE}
library(dplyr)
library(purrr)
library(data.table)
```

\newpage
\section{Introduction}

The zip file contains 332 comma-separated-value (CSV) files containing pollution monitoring data for fine particulate matter (PM) air pollution at 332 locations in the United States. Each file contains data from a single monitor and the ID number for each monitor is contained in the file name. For example, data for monitor 200 is contained in the file "200.csv". Each file contains three variables:

\begin{itemize}
  \item Date: the date of the observation in YYYY-MM-DD format (year-month-day);
  \item sulfate: the level of sulfate PM in the air on that date (measured in micrograms per cubic meter);
  \item nitrate: the level of nitrate PM in the air on that date (measured in micrograms per cubic meter).
\end{itemize}

For this programming assignment you will need to unzip this file and create the directory 'specdata'. Once you have unzipped the zip file, do not make any modifications to the files in the 'specdata' directory. In each file you'll notice that there are many days where either sulfate or nitrate (or both) are missing (coded as NA). This is common with air pollution monitoring data in the United States.

For each of the following exercises, we will create the solution using base R, tidyverse, and data.table, as different methods might be used for different situations.

\section{Part 1: Mean function}

Write a function named 'pollutantmean' that calculates the mean of a pollutant (sulfate or nitrate) across a specified list of monitors. The function 'pollutantmean' takes three arguments: 'directory', 'pollutant', and 'id'.

\subsection{Solution using base R}

```{r function base_r_mean}
# This function calculates the mean of a specified pollutant across a specified set of pollution monitors
pollutantmean <- function(directory, pollutant, id = 1:332) {
  # Initialise an empty numeric vector
  pollutant_concentration <- numeric()
  # Initialise a for-loop to loop over each monitor id
  for (i in id) {
    # Define the file paths to each CSV file
    file_paths <- file.path(directory, sprintf("%03d.csv", i))
    # Read the CSV file(s) into a data frame
    df_id <- read.csv(file_paths)
    # Extract the column with pollutant concentrations into the pollutant_concentration vector
    pollutant_concentration <- c(pollutant_concentration, df_id[[pollutant]])
  }
  # 
  mean(pollutant_concentration, na.rm = TRUE)
}

pollutantmean("specdata", "nitrate")
```

\subsection{Solution using tidyverse}

Instead of appending values manually, you can collect all the data at once and then summarise it. Here's how you might rewrite the entire pollutantmean function using the tidyverse style:

```{r function tidyverse_mean}
# This function calculates the mean of a specified pollutant across a specified set of pollution monitors
pollutantmean <- function(directory, pollutant, id = 1:332) {
  # Define the file paths to each CSV file
  file_paths <- file.path(directory, sprintf("%03d.csv", id))
  # Read the required files and extract the pollutant column
  pollutant_concentrations <- file_paths %>%
    # Use map_dfr to bind pollutant columns from selected files into a single vector
    purrr::map_dfr(~ read.csv(.x) %>% select({{pollutant}})) %>%
    pull({{pollutant}})
  # Calculate the mean
  mean(pollutant_concentrations, na.rm = TRUE)
}

pollutantmean("specdata", "nitrate", 1:10)
```

\subsection{Solution using data.table}

If your data contains 1 million rows or more, it is highly recommended to use the data.table package which is optimised for reading and processing large datasets efficiently:

```{r function data.table_mean}
# This function calculates the mean of a specified pollutant across a specified set of pollution monitors
pollutantmean <- function(directory, pollutant, id = 1:332) {
  # Initialise an empty numeric vector
  pollutant_concentrations <- numeric()
  # Initialise a for-loop to loop over each monitor id
  for (i in id) {
    # Define the file paths to each CSV file
    file_paths <- file.path(directory, sprintf("%03d.csv", i))
    # Read only the necessary columns into memory
    df <- fread(file_paths, select = pollutant)
    # Combine the data
    pollutant_concentrations <- c(pollutant_concentrations, df[[pollutant]])
  }
  # Calculate the mean
  mean(pollutant_concentrations, na.rm = TRUE)
}

pollutantmean("specdata", "nitrate", 1:10)
```

\section{Part 2: Complete cases function}

Write a function that reads a directory full of files and reports the number of completely observed cases in each data file. The function should return a data frame where the first column is the name of the file and the second column is the number of complete cases.

\subsection{Solution using base R}

```{r function base_r_completecases}
# This function reads a directory and reports the number of completely observed cases in each file within a specified set of files
complete <- function(directory, id = 1:332) {
  # Initialise an empty data frame to store results
  results <- data.frame(id = integer(), nobs = integer())
  # Initialise a for-loop to loop over each monitor id
  for (i in id) {
    # Define the file paths to each CSV file
    file_paths <- file.path(directory, sprintf("%03d.csv", i))
    # Read the CSV file(s) into a data frame
    df_id <- read.csv(file_paths)
    # Count the number of complete cases using the complete.cases function
    total_complete_cases <- sum(complete.cases(df_id))
    # Append the result to the results data frame
    results <- rbind(results, data.frame(id = i, nobs = total_complete_cases))
  }
  # Return the results data frame
  return(results)
}
```

\subsection{Solution using tidyverse}

```{r function tidyverse_completecases}
# This function reads a directory and reports the number of completely observed cases in each file within a specified set of files
complete <- function(directory, id = 1:332) {
  # Define the file paths to each CSV file
  file_paths <- file.path(directory, sprintf("%03d.csv", id))
  # Iterate over the file paths and count complete cases
  results <- dplyr::tibble(
    id = id,
    # Use map_int to apply a function to each file path
    # For each file, map_int reads the data and computes the number of complete cases
    nobs = purrr::map_int(file_paths, ~ {
      # Read the CSV file
      df <- read.csv(.x)
      # Count the number of complete cases
      sum(complete.cases(df))
    })
  )
  # Return the results data frame
  return(results)
}

complete("specdata", c(2, 4, 8, 10, 12))
```

\subsection{Solution using data.table}

```{r function data.table_completecases}
# This function reads a directory and reports the number of completely observed cases in each file within a specified set of files
complete <- function(directory, id = 1:332) {
  # Initialise an empty data.table to store results
  results <- data.table(id = integer(), nobs = integer())
  # Initialise a for-loop to loop over each monitor id
  for (i in id) {
    # Define the file paths to each CSV file
    file_paths <- file.path(directory, sprintf("%03d.csv", i))
    # Read the CSV file(s) as a data.table
    df_id <- fread(file_paths)
    # Count the number of complete cases using the complete.cases function
    total_complete_cases <- sum(complete.cases(df_id))
    # Append the result to the results data frame
    results <- rbind(results, data.frame(id = i, nobs = total_complete_cases))
  }
  # Return the results data.table
  return(results)
}

complete("specdata", c(2, 4, 8, 10, 12))
```

\section{Part 3: Correlation function}

Write a function that takes a directory of data files and a threshold for complete cases and calculates the correlation between sulfate and nitrate for monitor locations where the number of completely observed cases (on all variables) is greater than the threshold. The function should return a vector of correlations for the monitors that meet the threshold requirement. If no monitors meet the threshold requirement, then the function should return a numeric vector of length 0.

\subsection{Solution using base R}

```{r function base_r_correlation}
# This function calculates the correlation between sulfate and nitrate for monitor locations where complete cases > threshold
corr <- function(directory, threshold = 0) {
  # Get the number of complete cases for each monitor in the directory
  num_complete_cases <- complete(directory, 1:332)
  # Filter monitors based on threshold
  num_complete_cases_filtered <- num_complete_cases[num_complete_cases$nobs > threshold, ]
  # Initialise a vector for correlations
  correlations <- numeric()
  # Initialise a for-loop to loop over each monitor id
  for (i in num_complete_cases_filtered$id) {
    # Define the file paths to each CSV file
    file_paths <- file.path(directory, sprintf("%03d.csv", i))
    # Read the CSV file(s) into a data frame
    df_id <- read.csv(file_paths)
    # Calculate the correlation between sulfate and nitrate columns in df_id
    correlation_values <- cor(df_id$sulfate, df_id$nitrate, use = "complete.obs")
    # Append the correlation values to the empty correlations vector
    correlations <- c(correlations, correlation_values)
  }
  # Return the vector containing all the correlations for eligible monitors
  return(correlations)
}

cr <- corr("specdata", 400)
head(cr)
summary(cr)

cr <- corr("specdata", 2000)                
n <- length(cr)                
cr <- corr("specdata", 1000)                
cr <- sort(cr)
print(c(n, round(cr, 4)))
```

\subsection{Solution using tidyverse}

```{r function tidyverse_correlation}
# This function calculates the correlation between sulfate and nitrate for monitor locations where complete cases > threshold
corr <- function(directory, threshold) {
  # Get the number of complete cases for each monitor in the directory
  num_complete_cases <- complete(directory, 1:332)
  # Filter monitors based on threshold using dplyr
  num_complete_cases_filtered <- num_complete_cases %>%
    filter(nobs > threshold)
  # Calculate the correlations for each monitor in a tidyverse way
  correlations <- num_complete_cases_filtered %>%
    rowwise() %>%
    mutate(
      correlation = {
        # Define the file paths to each CSV file
        file_paths <- file.path(directory, sprintf("%03d.csv", id))
        # Read the CSV file(s) into a data frame
        df_id <- read.csv(file_paths)
        # Calculate the correlation between sulfate and nitrate columns in df_id
        cor(df_id$sulfate, df_id$nitrate, use = "complete.obs")
      }
    ) %>%
    pull(correlation)
  
  # Return the vector containing all the correlations for eligible monitors
  return(correlations)
}

cr <- corr("specdata", 400)
head(cr)
summary(cr)
```

\subsection{Solution using data.table}

```{r function data.table_correlation}
# This function calculates the correlation between sulfate and nitrate for monitor locations where complete cases > threshold
corr <- function(directory, threshold) {
  # Get the number of complete cases for each monitor in the directory
  num_complete_cases <- as.data.table(complete(directory, 1:332))
  # Filter monitors based on threshold
  num_complete_cases_filtered <- num_complete_cases[nobs > threshold]
  # Initialise a vector for correlations
  correlations <- numeric()
  # Initialise a for-loop to loop over each monitor id
  for (i in num_complete_cases_filtered$id) {
    # Define the file paths to each CSV file
    file_paths <- file.path(directory, sprintf("%03d.csv", i))
    # Read the CSV file(s) into a data frame
    df_id <- read.csv(file_paths)
    # Calculate the correlation between sulfate and nitrate columns in df_id
    correlation_values <- cor(df_id$sulfate, df_id$nitrate, use = "complete.obs")
    # Append the correlation values to the empty correlations vector
    correlations <- c(correlations, correlation_values)
  }
  # Return the vector containing all the correlations for eligible monitors
  return(correlations)
}

cr <- corr("specdata", 400)
head(cr)
summary(cr)
```



























